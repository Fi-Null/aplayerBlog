<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#CC543A">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#CC543A">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","width":240,"display":"post","offset":12,"onmobile":true},
    copycode: {"enable":true,"show_result":true,"style":"flat"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#CC543A","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="Es 的分布式架构原理ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。es 中存储数据的基本单位是索引，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql">
<meta property="og:type" content="article">
<meta property="og:title" content="Es基本知识">
<meta property="og:url" content="https://fi-null.github.io/2020/03/17/Es/index.html">
<meta property="og:site_name" content="Xk&#39;s | Blog">
<meta property="og:description" content="Es 的分布式架构原理ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。es 中存储数据的基本单位是索引，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/index.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_invert_index.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_list.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_index_struct.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_example.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_example1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/trie_tree.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_index_structure1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/skip_list.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/frame_of_reference.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/roaring_bitmap.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_compress.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_compress1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-write.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-write-detail.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-search-process.png">
<meta property="article:published_time" content="2020-03-17T09:24:37.000Z">
<meta property="article:modified_time" content="2020-04-05T13:34:05.841Z">
<meta property="article:author" content="Ke Xiang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es.png">
  <link rel="canonical" href="https://fi-null.github.io/2020/03/17/Es/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Es基本知识 | Xk's | Blog</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- MetingJS start -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css">
  <script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js"></script>
  <!-- MetingJS end -->
<script>
  (function(d) {
    var config = {
      kitId: 'tzu7ura',
      scriptTimeout: 3000,
      async: true
    },
    h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
  })(document);
</script>

  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xk's | Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish</h1>
      
    <!--
    -->
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resume">

    <a href="https://fi-null.github.io/resumeWeb" target="_blank" rel="section"><i class="fa fa-fw fa-handshake-o"></i>简历</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://fi-null.github.io/2020/03/17/Es/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Ke Xiang">
      <meta itemprop="description" content="Do more, Know more, Be more">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xk's | Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          Es基本知识
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-17 17:24:37" itemprop="dateCreated datePublished" datetime="2020-03-17T17:24:37+08:00">2020-03-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Es/" itemprop="url" rel="index">
                    <span itemprop="name">Es</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Es-的分布式架构原理"><a href="#Es-的分布式架构原理" class="headerlink" title="Es 的分布式架构原理"></a>Es 的分布式架构原理</h2><p>ElasticSearch 设计的理念就是分布式搜索引擎，底层其实还是基于 lucene 的。核心思想就是在多台机器上启动多个 es 进程实例，组成了一个 es 集群。</p><p>es 中存储数据的<strong>基本单位是索引</strong>，比如说你现在要在 es 中存储一些订单数据，你就应该在 es 中创建一个索引 <code>order_idx</code>，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是 mysql 里的一张表。</p><a id="more"></a>

<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index -&gt;<span class="built_in"> type </span>-&gt; mapping -&gt; document -&gt; field。</span><br></pre></td></tr></table></figure>

<p>这样吧，为了做个更直白的介绍，我在这里做个类比。但是切记，不要划等号，类比只是为了便于理解。</p>
<p>index 相当于 mysql 里的一张表。而 type 没法跟 mysql 里去对比，一个 index 里可以有多个 type，每个 type 的字段都是差不多的，但是有一些略微的差别。假设有一个 index，是订单 index，里面专门是放订单数据的。就好比说你在 mysql 中建表，有些订单是实物商品的订单，比如一件衣服、一双鞋子；有些订单是虚拟商品的订单，比如游戏点卡，话费充值。就两种订单大部分字段是一样的，但是少部分字段可能有略微的一些差别。</p>
<p>所以就会在订单 index 里，建两个 type，一个是实物商品订单 type，一个是虚拟商品订单 type，这两个 type 大部分字段是一样的，少部分字段是不一样的。</p>
<p>很多情况下，一个 index 里可能就一个 type，但是确实如果说是一个 index 里有多个 type 的情况（<strong>注意</strong>，<code>mapping types</code> 这个概念在 ElasticSearch 7.X 已被完全移除，详细说明可以参考<a href="https://github.com/elastic/elasticsearch/blob/6.5/docs/reference/mapping/removal_of_types.asciidoc" target="_blank" rel="noopener">官方文档</a>），你可以认为 index 是一个类别的表，具体的每个 type 代表了 mysql 中的一个表。每个 type 有一个 mapping，如果你认为一个 type 是具体的一个表，index 就代表多个 type 同属于的一个类型，而 mapping 就是这个 type 的<strong>表结构定义</strong>，你在 mysql 中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。实际上你往 index 里的一个 type 里面写的一条数据，叫做一条 document，一条 document 就代表了 mysql 中某个表里的一行，每个 document 有多个 field，每个 field 就代表了这个 document 中的一个字段的值。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es.png" alt></p>
<p>你搞一个索引，这个索引可以拆分成多个 <code>shard</code>，每个 shard 存储部分数据。拆分多个 shard 是有好处的，一是<strong>支持横向扩展</strong>，比如你数据量是 3T，3 个 shard，每个 shard 就 1T 的数据，若现在数据量增加到 4T，怎么扩展，很简单，重新建一个有 4 个 shard 的索引，将数据导进去；二是<strong>提高性能</strong>，数据分布在多个 shard，即多台服务器上，所有的操作，都会在多台机器上并行分布式执行，提高了吞吐量和性能。</p>
<p>接着就是这个 shard 的数据实际是有多个备份，就是说每个 shard 都有一个 <code>primary shard</code>，负责写入数据，但是还有几个 <code>replica shard</code>。<code>primary shard</code> 写入数据之后，会将数据同步到其他几个 <code>replica shard</code> 上去。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es1.png" alt></p>
<p>通过这个 replica 的方案，每个 shard 的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。</p>
<p>es 集群多个节点，会自动选举一个节点为 master 节点，这个 master 节点其实就是干一些管理的工作的，比如维护索引元数据、负责切换 primary shard 和 replica shard 身份等。要是 master 节点宕机了，那么会重新选举一个节点为 master 节点。</p>
<p>如果是非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard。接着你要是修复了那个宕机机器，重启了之后，master 节点会控制将缺失的 replica shard 分配过去，同步后续修改的数据之类的，让集群恢复正常。</p>
<p>说得更简单一点，就是说如果某个非 master 节点宕机了。那么此节点上的 primary shard 不就没了。那好，master 会让 primary shard 对应的 replica shard（在其他机器上）切换为 primary shard。如果宕机的机器修复了，修复后的节点也不再是 primary shard，而是 replica shard。</p>
<p>其实上述就是 ElasticSearch 作为分布式搜索引擎最基本的一个架构设计。</p>
<h3 id="底层-lucene"><a href="#底层-lucene" class="headerlink" title="底层 lucene"></a>底层 lucene</h3><p>简单来说，lucene 就是一个 jar 包，里面包含了封装好的各种建立倒排索引的算法代码。我们用 Java 开发的时候，引入 lucene jar，然后基于 lucene 的 api 去开发就可以了。</p>
<p>通过 lucene，我们可以将已有的数据建立索引，lucene 会在本地磁盘上面，给我们组织索引的数据结构。</p>
<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><h4 id="倒排索引与正排索引"><a href="#倒排索引与正排索引" class="headerlink" title="倒排索引与正排索引"></a>倒排索引与正排索引</h4><p><strong>倒排索引（Inverted Index）</strong> 也常被称为反向索引，是搜索引擎中非常重要的数据结构，为什么说它重要呢，我们首先拿一本书《重构 改善既有代码的设计》举个例子：</p>
<p>如果一本书没有目录的话，理论上也是可以读的，只是合上书下次再次阅读的时候，就有些耗费时间了。</p>
<p>通过给一本书加目录页，可以快速了解这本书的大致内容分布以及每个章节的页码数，这样在查询内容的时候效率就会非常高了，所以书的目录就是书本内容的简单索引。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/index.png" alt></p>
<p>想象一下你要搜索 <code>case语句</code> 这个关键词在这本书的页码，你应该怎么办呢？有些技术类的书籍会在最后提供索引页，这本书的索引页如下：</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_invert_index.png" alt></p>
<p>只需要从索引页中查找 <code>case语句</code>，就可以查找到关键词在书本中的页码位置了。</p>
<p>看完这个例子，让我们来把图书和搜索引擎做个简单的类比：</p>
<p>图书当中的<strong>目录页</strong>就相当<strong>正向索引（Forward Index）</strong>，<strong>索引页</strong>就相当于<strong>倒排索引</strong>的简单实现，在搜索引擎中，<strong>正向索引</strong>指的是<strong>文档 ID 到文档内容和单词的关联</strong>，<strong>倒排索引</strong>就是<strong>单词到文档 ID 的关系</strong>。</p>
<p>创建倒排索引，分为以下几步：</p>
<p>1）创建文档列表：</p>
<p>lucene首先对原始文档数据进行编号（DocID），形成列表，就是一个文档列表</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc.png" alt></p>
<p>2）创建倒排索引列表</p>
<p>对文档中数据进行分词，得到词条。对词条进行编号，以词条创建索引。然后记录下包含该词条的所有文档编号（及其它信息）。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_list.png" alt></p>
<p>搜索的过程：</p>
<p>当用户输入任意的词条时，首先对用户输入的数据进行分词，得到用户要搜索的所有词条，然后拿着这些词条去倒排索引列表中进行匹配。找到这些词条就能找到包含这些词条的所有文档的编号。然后根据这些编号去文档列表中找到文档</p>
<h4 id="倒排索引为什么快？"><a href="#倒排索引为什么快？" class="headerlink" title="倒排索引为什么快？"></a>倒排索引为什么快？</h4><p>​        Elasticsearch 是通过 Lucene 的倒排索引技术实现比关系型数据库更快的过滤。特别是它对多条件的过滤支持非常好，比如年龄在 18 和 30 之间，性别为女性这样的组合查询。倒排索引很多地方都有介绍，但是其比关系型数据库的 b-tree 索引快在哪里？到底为什么快呢？</p>
<p>​        笼统的来说，b-tree 索引是为写入优化的索引结构。当我们不需要支持快速的更新的时候，可以用预先排序等方式换取更小的存储空间，更快的检索速度等好处，其代价就是更新慢。要进一步深入的化，还是要看一下 Lucene 的倒排索引是怎么构成的。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_index_struct.png" alt></p>
<p>​        这里有好几个概念。我们来看一个实际的例子，假设有如下的数据：</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_example.png" alt></p>
<p>​        这里每一行是一个 document。每个 document 都有一个 docid。那么给这些 document 建立的倒排索引就是：年龄、性别。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_example1.png" alt></p>
<p>​        可以看到，倒排索引是 per field 的，一个字段由一个自己的倒排索引。18,20 这些叫做 term，而 [1,3] 就是 posting list。Posting list 就是一个 int 的数组，存储了所有符合某个 term 的文档 id。那么什么是 term dictionary 和 term index？</p>
<p>​        假设我们有很多个 term，比如：</p>
<p>​        <strong>Carla,Sara,Elin,Ada,Patty,Kate,Selena</strong></p>
<p>​        如果按照这样的顺序排列，找出某个特定的 term 一定很慢，因为 term 没有排序，需要全部过滤一遍才能找出特定的 term。排序之后就变成了：</p>
<p>​        <strong>Ada,Carla,Elin,Kate,Patty,Sara,Selena</strong></p>
<p>​        这样我们可以用二分查找的方式，比全遍历更快地找出目标的 term。这个就是 term dictionary。有了 term dictionary 之后，可以用 logN 次磁盘查找得到目标。但是磁盘的随机读操作仍然是非常昂贵的（一次 random access 大概需要 10ms 的时间）。所以尽量少的读磁盘，有必要把一些数据缓存到内存里。但是整个 term dictionary 本身又太大了，无法完整地放到内存里。于是就有了 term index。term index 有点像一本字典的大的章节表。比如：</p>
<p>​        如果所有的 term 都是英文字符的话，可能这个 term index 就真的是 26 个英文字符表构成的了。但是实际的情况是，term 未必都是英文字符，term 可以是任意的 byte 数组。而且 26 个英文字符也未必是每一个字符都有均等的 term，比如 x 字符开头的 term 可能一个都没有，而 s 开头的 term 又特别多。实际的 term index 是一棵 trie 树：</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/trie_tree.png" alt></p>
<p>​        例子是一个包含 “A”, “to”, “tea”, “ted”, “ten”, “i”, “in”, 和 “inn” 的 trie 树。这棵树不会包含所有的 term，它包含的是 term 的一些前缀。通过 term index 可以快速地定位到 term dictionary 的某个 offset，然后从这个位置再往后顺序查找。再加上一些压缩技术（搜索 Lucene Finite State Transducers） term index 的尺寸可以只有所有 term 的尺寸的几十分之一，使得用内存缓存整个 term index 变成可能。整体上来说就是这样的效果。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_index_structure1.png" alt></p>
<p>​        现在我们可以回答“为什么 Elasticsearch/Lucene 检索可以比 mysql 快了。Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次的 random access 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了 term index 来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access 次数。</p>
<p>​        额外值得一提的两点是：term index 在内存中是以 FST（finite state transducers）的形式保存的，其特点是非常节省内存。Term dictionary 在磁盘上是以分 block 的方式保存的，一个 block 内部利用公共前缀压缩，比如都是 Ab 开头的单词就可以把 Ab 省去。这样 term dictionary 可以比 b-tree 更节约磁盘空间。</p>
<h4 id="如何联合索引查询？"><a href="#如何联合索引查询？" class="headerlink" title="如何联合索引查询？"></a>如何联合索引查询？</h4><p>​        所以给定查询过滤条件 age=18 的过程就是先从 term index 找到 18 在 term dictionary 的大概位置，然后再从 term dictionary 里精确地找到 18 这个 term，然后得到一个 posting list 或者一个指向 posting list 位置的指针。然后再查询 gender= 女 的过程也是类似的。最后得出 age=18 AND gender= 女 就是把两个 posting list 做一个“与”的合并。</p>
<p>​        这个理论上的“与”合并的操作可不容易。对于 mysql 来说，如果你给 age 和 gender 两个字段都建立了索引，查询的时候只会选择其中最 selective 的来用，然后另外一个条件是在遍历行的过程中在内存中计算之后过滤掉。那么要如何才能联合使用两个索引呢？有两种办法：</p>
<ul>
<li>使用 skip list 数据结构。同时遍历 gender 和 age 的 posting list，互相 skip；</li>
<li>使用 bitset 数据结构，对 gender 和 age 两个 filter 分别求出 bitset，对两个 bitset 做 AND 操作。</li>
</ul>
<p>PostgreSQL 从 8.4 版本开始支持通过 bitmap 联合使用两个索引，就是利用了 bitset 数据结构来做到的。当然一些商业的关系型数据库也支持类似的联合索引的功能。Elasticsearch 支持以上两种的联合索引方式，如果查询的 filter 缓存到了内存中（以 bitset 的形式），那么合并就是两个 bitset 的 AND。如果查询的 filter 没有缓存，那么就用 skip list 的方式去遍历两个 on disk 的 posting list。</p>
<p><strong>利用 Skip List 合并</strong></p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/skip_list.png" alt></p>
<p>​        以上是三个 posting list。我们现在需要把它们用 AND 的关系合并，得出 posting list 的交集。首先选择最短的 posting list，然后从小到大遍历。遍历的过程可以跳过一些元素，比如我们遍历到绿色的 13 的时候，就可以跳过蓝色的 3 了，因为 3 比 13 要小。</p>
<p>​        整个过程如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Next -&gt; <span class="number">2</span></span><br><span class="line">Advance(<span class="number">2</span>) -&gt; <span class="number">13</span></span><br><span class="line">Advance(<span class="number">13</span>) -&gt; <span class="number">13</span></span><br><span class="line">Already on <span class="number">13</span></span><br><span class="line">Advance(<span class="number">13</span>) -&gt; <span class="number">13</span> MATCH!!!</span><br><span class="line">Next -&gt; <span class="number">17</span></span><br><span class="line">Advance(<span class="number">17</span>) -&gt; <span class="number">22</span></span><br><span class="line">Advance(<span class="number">22</span>) -&gt; <span class="number">98</span></span><br><span class="line">Advance(<span class="number">98</span>) -&gt; <span class="number">98</span></span><br><span class="line">Advance(<span class="number">98</span>) -&gt; <span class="number">98</span> MATCH!!!</span><br></pre></td></tr></table></figure>

<p>​        最后得出的交集是 [13,98]，所需的时间比完整遍历三个 posting list 要快得多。但是前提是每个 list 需要指出 Advance 这个操作，快速移动指向的位置。</p>
<p>​        从概念上来说，对于一个很长的 posting list，比如：</p>
<p>​        [1,3,13,101,105,108,255,256,257]</p>
<p>​        我们可以把这个 list 分成三个 block：</p>
<p>​        [1,3,13] [101,105,108] [255,256,257]</p>
<p>​        然后可以构建出 skip list 的第二层：</p>
<p>​        [1,101,255]</p>
<p>​        1,101,255 分别指向自己对应的 block。这样就可以很快地跨 block 的移动指向位置了。</p>
<p>​        Lucene 自然会对这个 block 再次进行压缩。其压缩方式叫做 Frame Of Reference 编码。示例如下：</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/frame_of_reference.png" alt></p>
<p>​        考虑到频繁出现的 term（所谓 low cardinality 的值），比如 gender 里的男或者女。如果有 1 百万个文档，那么性别为男的 posting list 里就会有 50 万个 int 值。用 Frame of Reference 编码进行压缩可以极大减少磁盘占用。这个优化对于减少索引尺寸有非常重要的意义。当然 mysql b-tree 里也有一个类似的 posting list 的东西，是未经过这样压缩的。</p>
<p>​        因为这个 Frame of Reference 的编码是有解压缩成本的。利用 skip list，除了跳过了遍历的成本，也跳过了解压缩这些压缩过的 block 的过程，从而节省了 cpu。</p>
<p><strong>利用 bitset 合并</strong></p>
<p>Bitset 是一种很直观的数据结构，对应 posting list 如：</p>
<p>[1,3,4,7,10]</p>
<p>对应的 bitset 就是：</p>
<p>[1,0,1,1,0,0,1,0,0,1]</p>
<p>每个文档按照文档 id 排序对应其中的一个 bit。Bitset 自身就有压缩的特点，其用一个 byte 就可以代表 8 个文档。所以 100 万个文档只需要 12.5 万个 byte。但是考虑到文档可能有数十亿之多，在内存里保存 bitset 仍然是很奢侈的事情。而且对于个每一个 filter 都要消耗一个 bitset，比如 age=18 缓存起来的话是一个 bitset，18&lt;=age&lt;25 是另外一个 filter 缓存起来也要一个 bitset。</p>
<p>所以秘诀就在于需要有一个数据结构：</p>
<ul>
<li>可以很压缩地保存上亿个 bit 代表对应的文档是否匹配 filter；</li>
<li>这个压缩的 bitset 仍然可以很快地进行 AND 和 OR 的逻辑操作。</li>
</ul>
<p>Lucene 使用的这个数据结构叫做 Roaring Bitmap。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/roaring_bitmap.png" alt></p>
<p>其压缩的思路其实很简单。与其保存 100 个 0，占用 100 个 bit。还不如保存 0 一次，然后声明这个 0 重复了 100 遍。</p>
<p>这两种合并使用索引的方式都有其用途。Elasticsearch 对其性能有详细的对比（<a href="https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps" target="_blank" rel="noopener"> https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps </a>）。简单的结论是：因为 Frame of Reference 编码是如此高效，对于简单的相等条件的过滤缓存成纯内存的 bitset 还不如需要访问磁盘的 skip list 的方式要快。</p>
<h4 id="如何减少文档数？"><a href="#如何减少文档数？" class="headerlink" title="如何减少文档数？"></a>如何减少文档数？</h4><p>一种常见的压缩存储时间序列的方式是把多个数据点合并成一行。Opentsdb 支持海量数据的一个绝招就是定期把很多行数据合并成一行，这个过程叫 compaction。类似的 vivdcortext 使用 mysql 存储的时候，也把一分钟的很多数据点合并存储到 mysql 的一行里以减少行数。</p>
<p>这个过程可以示例如下：</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_compress.png" alt></p>
<p>可以看到，行变成了列了。每一列可以代表这一分钟内一秒的数据。</p>
<p>Elasticsearch有一个功能可以实现类似的优化效果，那就是Nested Document。我们可以把一段时间的很多个数据点打包存储到一个父文档里，变成其嵌套的子文档。示例如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;timestamp:12:05:01, idc:sz, value1:10,value2:11&#125;</span><br><span class="line">&#123;timestamp:12:05:02, idc:sz, value1:9,value2:9&#125;</span><br><span class="line">&#123;timestamp:12:05:02, idc:sz, value1:18,value:17&#125;</span><br></pre></td></tr></table></figure>

<p>可以打包成：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    max_timestamp:12:05:02, min_timestamp: 1205:01, idc:sz,</span><br><span class="line">    records: [</span><br><span class="line">        &#123;timestamp:12:05:01, value1:10, value2:11&#125;</span><br><span class="line">    		&#123;timestamp:12:05:02, value1:9, value2:9&#125;</span><br><span class="line">    		&#123;timestamp:12:05:02, value1:18, value:17&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样可以把数据点公共的维度字段上移到父文档里，而不用在每个子文档里重复存储，从而减少索引的尺寸。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es_doc_compress1.png" alt></p>
<p>在存储的时候，无论父文档还是子文档，对于 Lucene 来说都是文档，都会有文档 Id。但是对于嵌套文档来说，可以保存起子文档和父文档的文档 id 是连续的，而且父文档总是最后一个。有这样一个排序性作为保障，那么有一个所有父文档的 posting list 就可以跟踪所有的父子关系。也可以很容易地在父子文档 id 之间做转换。把父子关系也理解为一个 filter，那么查询时检索的时候不过是又 AND 了另外一个 filter 而已。前面我们已经看到了 Elasticsearch 可以非常高效地处理多 filter 的情况，充分利用底层的索引。</p>
<p>使用了嵌套文档之后，对于 term 的 posting list 只需要保存父文档的 doc id 就可以了，可以比保存所有的数据点的 doc id 要少很多。如果我们可以在一个父文档里塞入 50 个嵌套文档，那么 posting list 可以变成之前的 1/50。</p>
<h3 id="es-写数据过程"><a href="#es-写数据过程" class="headerlink" title="es 写数据过程"></a>es 写数据过程</h3><ul>
<li>客户端选择一个 node 发送请求过去，这个 node 就是 <code>coordinating node</code>（协调节点）。</li>
<li><code>coordinating node</code> 对 document 进行<strong>路由</strong>，将请求转发给对应的 node（有 primary shard）。</li>
<li>实际的 node 上的 <code>primary shard</code> 处理请求，然后将数据同步到 <code>replica node</code>。</li>
<li><code>coordinating node</code> 如果发现 <code>primary node</code> 和所有 <code>replica node</code> 都搞定之后，就返回响应结果给客户端。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-write.png" alt></p>
<h3 id="es-读数据过程"><a href="#es-读数据过程" class="headerlink" title="es 读数据过程"></a>es 读数据过程</h3><p>可以通过 <code>doc id</code> 来查询，会根据 <code>doc id</code> 进行 hash，判断出来当时把 <code>doc id</code> 分配到了哪个 shard 上面去，从那个 shard 去查询。</p>
<ul>
<li>客户端发送请求到<strong>任意</strong>一个 node，成为 <code>coordinate node</code>。</li>
<li><code>coordinate node</code> 对 <code>doc id</code> 进行哈希路由，将请求转发到对应的 node，此时会使用 <code>round-robin</code> <strong>随机轮询算法</strong>，在 <code>primary shard</code> 以及其所有 replica 中随机选择一个，让读请求负载均衡。</li>
<li>接收请求的 node 返回 document 给 <code>coordinate node</code>。</li>
<li><code>coordinate node</code> 返回 document 给客户端。</li>
</ul>
<h3 id="es-搜索数据过程"><a href="#es-搜索数据过程" class="headerlink" title="es 搜索数据过程"></a>es 搜索数据过程</h3><p>es 最强大的是做全文检索，就是比如你有三条数据：</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">java真好玩儿啊</span></span><br><span class="line"><span class="keyword">java好难学啊</span></span><br><span class="line"><span class="keyword">j2ee特别牛</span></span><br></pre></td></tr></table></figure>

<p>你根据 <code>java</code> 关键词来搜索，将包含 <code>java</code>的 <code>document</code> 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。</p>
<ul>
<li>客户端发送请求到一个 <code>coordinate node</code>。</li>
<li>协调节点将搜索请求转发到<strong>所有</strong>的 shard 对应的 <code>primary shard</code> 或 <code>replica shard</code>，都可以。</li>
<li>query phase：每个 shard 将自己的搜索结果（其实就是一些 <code>doc id</code>）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。</li>
<li>fetch phase：接着由协调节点根据 <code>doc id</code> 去各个节点上<strong>拉取实际</strong>的 <code>document</code> 数据，最终返回给客户端。</li>
</ul>
<blockquote>
<p>写请求是写入 primary shard，然后同步给所有的 replica shard；读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。</p>
</blockquote>
<h3 id="写数据底层原理"><a href="#写数据底层原理" class="headerlink" title="写数据底层原理"></a>写数据底层原理</h3><p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-write-detail.png" alt></p>
<p>先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。</p>
<p>如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 <code>refresh</code> 到一个新的 <code>segment file</code> 中，但是此时数据不是直接进入 <code>segment file</code> 磁盘文件，而是先进入 <code>os cache</code> 。这个过程就是 <code>refresh</code>。</p>
<p>每隔 1 秒钟，es 将 buffer 中的数据写入一个<strong>新的</strong> <code>segment file</code>，每秒钟会产生一个<strong>新的磁盘文件</strong> <code>segment file</code>，这个 <code>segment file</code> 中就存储最近 1 秒内 buffer 中写入的数据。</p>
<p>但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。</p>
<p>操作系统里面，磁盘文件其实都有一个东西，叫做 <code>os cache</code>，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 <code>os cache</code>，先进入操作系统级别的一个内存缓存中去。只要 <code>buffer</code> 中的数据被 refresh 操作刷入 <code>os cache</code>中，这个数据就可以被搜索到了。</p>
<p>为什么叫 es 是<strong>准实时</strong>的？ <code>NRT</code>，全称 <code>near real-time</code>。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 <code>restful api</code> 或者 <code>java api</code>，<strong>手动</strong>执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 <code>os cache</code>中，让数据立马就可以被搜索到。只要数据被输入 <code>os cache</code> 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。</p>
<p>重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 <code>buffer</code> 数据写入一个又一个新的 <code>segment file</code> 中去，每次 <code>refresh</code> 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 <code>commit</code> 操作。</p>
<p>commit 操作发生第一步，就是将 buffer 中现有数据 <code>refresh</code> 到 <code>os cache</code> 中去，清空 buffer。然后，将一个 <code>commit point</code> 写入磁盘文件，里面标识着这个 <code>commit point</code> 对应的所有 <code>segment file</code>，同时强行将 <code>os cache</code> 中目前所有的数据都 <code>fsync</code> 到磁盘文件中去。最后<strong>清空</strong> 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。</p>
<p>这个 commit 操作叫做 <code>flush</code>。默认 30 分钟自动执行一次 <code>flush</code>，但如果 translog 过大，也会触发 <code>flush</code>。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。</p>
<p>translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 <code>translog</code> 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。</p>
<p>translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会<strong>丢失</strong> 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 <code>fsync</code> 到磁盘，但是性能会差很多。</p>
<p>实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的<strong>数据丢失</strong>。</p>
<p><strong>总结一下</strong>，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。</p>
<blockquote>
<p>数据写入 segment file 之后，同时就建立好了倒排索引。</p>
</blockquote>
<h3 id="删除-更新数据底层原理"><a href="#删除-更新数据底层原理" class="headerlink" title="删除/更新数据底层原理"></a>删除/更新数据底层原理</h3><p>如果是删除操作，commit 的时候会生成一个 <code>.del</code> 文件，里面将某个 doc 标识为 <code>deleted</code> 状态，那么搜索的时候根据 <code>.del</code> 文件就知道这个 doc 是否被删除了。</p>
<p>如果是更新操作，就是将原来的 doc 标识为 <code>deleted</code> 状态，然后新写入一条数据。</p>
<p>buffer 每 refresh 一次，就会产生一个 <code>segment file</code>，所以默认情况下是 1 秒钟一个 <code>segment file</code>，这样下来 <code>segment file</code> 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 <code>segment file</code> 合并成一个，同时这里会将标识为 <code>deleted</code> 的 doc 给<strong>物理删除掉</strong>，然后将新的 <code>segment file</code> 写入磁盘，这里会写一个 <code>commit point</code>，标识所有新的 <code>segment file</code>，然后打开 <code>segment file</code> 供搜索使用，同时删除旧的 <code>segment file</code>。</p>
<h3 id="es-在数据量很大的情况下（数十亿级别）如何提高查询效率"><a href="#es-在数据量很大的情况下（数十亿级别）如何提高查询效率" class="headerlink" title="es 在数据量很大的情况下（数十亿级别）如何提高查询效率"></a>es 在数据量很大的情况下（数十亿级别）如何提高查询效率</h3><h3 id="性能优化的杀手锏——filesystem-cache"><a href="#性能优化的杀手锏——filesystem-cache" class="headerlink" title="性能优化的杀手锏——filesystem cache"></a>性能优化的杀手锏——filesystem cache</h3><p>你往 es 里写的数据，实际上都写到磁盘文件里去了，<strong>查询的时候</strong>，操作系统会将磁盘文件里的数据自动缓存到 <code>filesystem cache</code> 里面去。</p>
<p><img src="https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/es/es-search-process.png" alt></p>
<p>es 的搜索引擎严重依赖于底层的 <code>filesystem cache</code>，你如果给 <code>filesystem cache</code> 更多的内存，尽量让内存可以容纳所有的 <code>idx segment file</code>索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。</p>
<p>性能差距究竟可以有多大？我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒、5秒、10秒。但如果是走 <code>filesystem cache</code>，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。</p>
<p>这里有个真实的案例。某个公司 es 节点有 3 台机器，每台机器看起来内存很多，64G，总内存就是 <code>64 * 3 = 192G</code>。每台机器给 es jvm heap 是 <code>32G</code>，那么剩下来留给 <code>filesystem cache</code> 的就是每台机器才 <code>32G</code>，总共集群里给 <code>filesystem cache</code> 的就是 <code>32 * 3 = 96G</code> 内存。而此时，整个磁盘上索引数据文件，在 3 台机器上一共占用了 <code>1T</code> 的磁盘容量，es 数据量是 <code>1T</code>，那么每台机器的数据量是 <code>300G</code>。这样性能好吗？ <code>filesystem cache</code> 的内存才 100G，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差。</p>
<p>归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。</p>
<p>根据我们自己的生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，就是你要<strong>用来搜索的那些索引</strong>，如果内存留给 <code>filesystem cache</code> 的是 100G，那么你就将索引数据控制在 <code>100G</code> 以内，这样的话，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。</p>
<p>比如说你现在有一行数据。<code>id,name,age ....</code> 30 个字段。但是你现在搜索，只需要根据 <code>id,name,age</code> 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 <code>90%</code> 的数据是不用来搜索的，结果硬是占据了 es 机器上的 <code>filesystem cache</code> 的空间，单条数据的数据量越大，就会导致 <code>filesystem cahce</code> 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的<strong>少数几个字段</strong>就可以了，比如说就写入 es <code>id,name,age</code> 三个字段，然后你可以把其他的字段数据存在 mysql/hbase 里，我们一般是建议用 <code>es + hbase</code> 这么一个架构。</p>
<p>hbase 的特点是<strong>适用于海量数据的在线存储</strong>，就是对 hbase 可以写入海量数据，但是不要做复杂的搜索，做很简单的一些根据 id 或者范围进行查询的这么一个操作就可以了。从 es 中根据 name 和 age 去搜索，拿到的结果可能就 20 个 <code>doc id</code>，然后根据 <code>doc id</code> 到 hbase 里去查询每个 <code>doc id</code> 对应的<strong>完整的数据</strong>，给查出来，再返回给前端。</p>
<p>写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms，可能你原来那么玩儿，1T 数据都放 es，会每次查询都是 5~10s，现在可能性能就会很高，每次查询就是 50ms。</p>
<h3 id="数据预热"><a href="#数据预热" class="headerlink" title="数据预热"></a>数据预热</h3><p>假如说，哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 <code>filesystem cache</code> 一倍，比如说你写入一台机器 60G 数据，结果 <code>filesystem cache</code> 就 30G，还是有 30G 数据留在了磁盘上。</p>
<p>其实可以做<strong>数据预热</strong>。</p>
<p>举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 <code>filesystem cache</code> 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。</p>
<p>或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 <code>filesystem cache</code> 里去。</p>
<p>对于那些你觉得比较热的、经常会有人访问的数据，最好<strong>做一个专门的缓存预热子系统</strong>，就是对热数据每隔一段时间，就提前访问一下，让数据进入 <code>filesystem cache</code> 里面去。这样下次别人访问的时候，性能一定会好很多。</p>
<h3 id="冷热分离"><a href="#冷热分离" class="headerlink" title="冷热分离"></a>冷热分离</h3><p>es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将<strong>冷数据写入一个索引中，然后热数据写入另外一个索引中</strong>，这样可以确保热数据在被预热之后，尽量都让他们留在 <code>filesystem os cache</code> 里，<strong>别让冷数据给冲刷掉</strong>。</p>
<p>你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 <code>filesystem cache</code> 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。</p>
<h3 id="document-模型设计"><a href="#document-模型设计" class="headerlink" title="document 模型设计"></a>document 模型设计</h3><p>对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。</p>
<p>最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。</p>
<p>document 模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es 能支持的操作就那么多，不要考虑用 es 做一些它不好操作的事情。如果真的有那种操作，尽量在 document 模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的。</p>
<h3 id="分页性能优化"><a href="#分页性能优化" class="headerlink" title="分页性能优化"></a>分页性能优化</h3><p>es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。</p>
<p>分布式的，你要查第 100 页的 10 条数据，不可能说从 5 个 shard，每个 shard 就查 2 条数据，最后到协调节点合并成 10 条数据吧？你<strong>必须</strong>得从每个 shard 都查 1000 条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第 100 页的数据。你翻页的时候，翻的越深，每个 shard 返回的数据就越多，而且协调节点处理的时间越长，非常坑爹。所以用 es 做分页的时候，你会发现越翻到后面，就越是慢。</p>
<p>我们之前也是遇到过这个问题，用 es 作分页，前几页就几十毫秒，翻到 10 页或者几十页的时候，基本上就要 5~10 秒才能查出来一页数据了。</p>
<p>有什么解决方案吗？</p>
<h4 id="不允许深度分页（默认深度分页性能很差）"><a href="#不允许深度分页（默认深度分页性能很差）" class="headerlink" title="不允许深度分页（默认深度分页性能很差）"></a>不允许深度分页（默认深度分页性能很差）</h4><p>跟产品经理说，你系统不允许翻那么深的页，默认翻的越深，性能就越差。</p>
<h4 id="类似于-app-里的推荐商品不断下拉出来一页一页的"><a href="#类似于-app-里的推荐商品不断下拉出来一页一页的" class="headerlink" title="类似于 app 里的推荐商品不断下拉出来一页一页的"></a>类似于 app 里的推荐商品不断下拉出来一页一页的</h4><p>类似于微博中，下拉刷微博，刷出来一页一页的，你可以用 <code>scroll api</code>，关于如何使用，自行上网搜索。</p>
<p>scroll 会一次性给你生成<strong>所有数据的一个快照</strong>，然后每次滑动向后翻页就是通过<strong>游标</strong> <code>scroll_id</code> 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。</p>
<p>但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，<strong>不能随意跳到任何一页的场景</strong>。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。</p>
<p>初始化时必须指定 <code>scroll</code> 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。</p>
<p>除了用 <code>scroll api</code>，你也可以用 <code>search_after</code> 来做，<code>search_after</code> 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。</p>

    </div>

    
    
    

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/03/16/WebSocket/" rel="next" title="WebSocket">
                  <i class="fa fa-chevron-left"></i> WebSocket
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/03/17/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F/" rel="prev" title="如何设计一个高并发系统">
                  如何设计一个高并发系统 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Es-的分布式架构原理"><span class="nav-number">1.</span> <span class="nav-text">Es 的分布式架构原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#底层-lucene"><span class="nav-number">1.1.</span> <span class="nav-text">底层 lucene</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#倒排索引"><span class="nav-number">1.2.</span> <span class="nav-text">倒排索引</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#倒排索引与正排索引"><span class="nav-number">1.2.1.</span> <span class="nav-text">倒排索引与正排索引</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#倒排索引为什么快？"><span class="nav-number">1.2.2.</span> <span class="nav-text">倒排索引为什么快？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何联合索引查询？"><span class="nav-number">1.2.3.</span> <span class="nav-text">如何联合索引查询？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#如何减少文档数？"><span class="nav-number">1.2.4.</span> <span class="nav-text">如何减少文档数？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-写数据过程"><span class="nav-number">1.3.</span> <span class="nav-text">es 写数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-读数据过程"><span class="nav-number">1.4.</span> <span class="nav-text">es 读数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-搜索数据过程"><span class="nav-number">1.5.</span> <span class="nav-text">es 搜索数据过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#写数据底层原理"><span class="nav-number">1.6.</span> <span class="nav-text">写数据底层原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除-更新数据底层原理"><span class="nav-number">1.7.</span> <span class="nav-text">删除&#x2F;更新数据底层原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#es-在数据量很大的情况下（数十亿级别）如何提高查询效率"><span class="nav-number">1.8.</span> <span class="nav-text">es 在数据量很大的情况下（数十亿级别）如何提高查询效率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#性能优化的杀手锏——filesystem-cache"><span class="nav-number">1.9.</span> <span class="nav-text">性能优化的杀手锏——filesystem cache</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据预热"><span class="nav-number">1.10.</span> <span class="nav-text">数据预热</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#冷热分离"><span class="nav-number">1.11.</span> <span class="nav-text">冷热分离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#document-模型设计"><span class="nav-number">1.12.</span> <span class="nav-text">document 模型设计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分页性能优化"><span class="nav-number">1.13.</span> <span class="nav-text">分页性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#不允许深度分页（默认深度分页性能很差）"><span class="nav-number">1.13.1.</span> <span class="nav-text">不允许深度分页（默认深度分页性能很差）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#类似于-app-里的推荐商品不断下拉出来一页一页的"><span class="nav-number">1.13.2.</span> <span class="nav-text">类似于 app 里的推荐商品不断下拉出来一页一页的</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Ke Xiang"
    src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Ke Xiang</p>
  <div class="site-description" itemprop="description">Do more, Know more, Be more</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fi-null" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;fi-null" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xk123401@foxmail.com" title="E-Mail &amp;rarr; mailto:xk123401@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/xk123401" title="Weibo &amp;rarr; https:&#x2F;&#x2F;weibo.com&#x2F;xk123401" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/profiles/76561198313695590/" title="Steam &amp;rarr; https:&#x2F;&#x2F;steamcommunity.com&#x2F;profiles&#x2F;76561198313695590&#x2F;" rel="noopener" target="_blank"><i class="fa fa-fw fa-steam"></i>Steam</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 2018 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ke & Xiang</span>
</div>

        
<div class="busuanzi-count">
  <script pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/pjax/pjax.min.js?v=0.2.8"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

<script src="/js/utils.js?v=7.4.1.js"></script>

<script src="/js/motion.js?v=7.4.1.js"></script>


<script src="/js/schemes/pisces.js?v=7.4.1.js"></script>


<script src="/js/next-boot.js?v=7.4.1.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      element.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script pjax>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>






  
<script src="/js/local-search.js?v=7.4.1.js"></script>













    <div id="pjax">

  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/macyrate/gitalk@2.0.0/dist/gitalk.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/gh/macyrate/gitalk@2.0.0/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: 'aa2288c6cbb5322cac6b',
      clientSecret: '63492ee584a83a8479f1408f33e2ca04e3ef9f82',
      repo: 'fi-null.github.io',
      owner: 'fi-null',
      admin: ['fi-null'],
      id: '7e42e8a021ed4d59a6b0f9208a043929',
        language: 'zh-CN',
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

    </div>
</body>
<div id="contentleft">
  <div class="aplayer" 
  data-id="388713953" 
  data-server="netease" 
  data-type="playlist" 
  data-fixed="true" 
  data-autoplay="true" 
  data-order="random" 
  data-volume="0.5" 
  data-theme="#cc543a" 
  date-preload="auto" 
  ></div>
  <meting-js
	server="netease"
	type="playlist"
	id="60198">
</meting-js>
</div>
</html>