---
title: 左神算法班笔记-哈希
date: 2020-03-10 22:44:58
category:
- 左神算法
- 哈希
---

# 哈希

## 哈希函数

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/hash.png) 

>  百科：**散列函数**（英语：Hash function）又称**散列算法**、**哈希函数**，是一种从任何一种数据中创建小的**数字**“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将输入域中的数据打乱混合，重新创建一个叫做**散列值**（hash values，hash codes，hash sums，或hashes）的指纹。

### 哈希函数的性质

哈希函数的输入域可以是非常大的范围，比如，任意一个字符串，但是输出域是固定的范围（一定位数的bit），假设为S，并具有如下性质：

1. 典型的哈希函数都有无限的输入值域。
2. 当给哈希函数传入相同的输入值时，返回值一样。
3. 当给哈希函数传入不同的输入值时，返回值可能一样，也可能不一样，这时当然的，因为输出域统一是S，所以会有不同的输入值对应在S中的一个元素上（这种情况称为 **哈希冲突**）。
4. 最重要的性质是很多不同的输入值所得到的返回值会均匀分布在S上。

前3点性质是哈希函数的基础，第4点是评价一个哈希函数优劣的关键，不同输入值所得到的所有返回值越均匀地分布在S上，哈希函数越优秀，并且这种均匀分布与输入值出现的规律无关。比如，“aaa1”、“aaa2”、“aaa3”三个输入值比较类似，但经过优秀的哈希函数计算后得到的结果应该相差非常大。

### 哈希函数的经典实现

> 参考文献：[哈希函数的介绍](http://www.alloyteam.com/2017/05/hash-functions-introduction/)

比如使用MD5对“test”和“test1”两个字符串哈希的结果如下（哈希结果为128个bit，数据范围为`0~(2^128)-1`，通常转换为32个16进制数显示）：

```
test	098f6bcd4621d373cade4e832627b4f6
test1 5a105e8b9d40e1329780d62ea2265d8a
```

## 哈希表

> 百科：**散列表**（**Hash table**，也叫**哈希表**），是根据[键](https://zh.wikipedia.org/wiki/鍵)（Key）而直接访问在内存存储位置的[数据结构](https://zh.wikipedia.org/wiki/数据结构)。也就是说，它通过计算一个关于键值的函数，将所需查询的数据[映射](https://zh.wikipedia.org/wiki/映射)到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做[散列函数](https://zh.wikipedia.org/wiki/散列函数)，存放记录的数组称做**散列表**。

### 哈希表的经典实现

哈希表初始会有一个大小，比如16，表中每个元素都可以通过数组下标（0~~15）访问。每个元素可以看做一个桶，当要往表里放数据时，将要存放的数据的键值通过哈希函数计算出的哈希值模上16，结果正好对应0~~15，将这条数据放入对应下标的桶中。

那么当数据量超过16时，势必会存在哈希冲突（两条数据经哈希计算后放入同一个桶中），这时的解决方案就是将后一条入桶的数据作为后继结点链入到桶中已有的数据之后，如此，每个桶中存放的就是一个链表。那么这就是哈希表的经典结构：

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/hash1.png) 

当数据量较少时，哈希表的增删改查操作的时间复杂度都是`O(N)`的。因为根据一个键值就能定位一个桶，即使存在哈希冲突（桶里不只一条数据），但只要哈希函数优秀，数据量几乎均分在每个桶上（这样很少有哈希冲突，即使有，一个桶里也只会有很少的几条数据），那就在遍历一下桶里的链表比较键值进一步定位数据即可（反正链表很短）。

### 哈希表扩容

如果哈希表大小为16，对于样本规模N（要存储的数据数量）来说，如果N较小，那么根据哈希函数的散列特性，每个桶会均分这N条数据，这样落到每个桶的数据量也较小，不会影响哈希表的存取效率（这是由桶的链表长度决定的，因为存数据要往链表尾追加首先就要遍历得到尾结点，取数据要遍历链表比较键值）；但如果N较大，那么每个桶里都有`N/16`条数据，存取效率就变成`O(N)`了。因此哈希表哈需要一个扩容机制，当表中某个桶的数据量超过一个阀值时（`O(1)`到`O(N)`的转变，这需要一个算法来权衡），需要将哈希表扩容（一般是成倍的）。

扩容步骤是，创建一个新的较大的哈希表（假如大小为m），将原哈希表中的数据取出，将键值的哈希值模上m，放入新表对应的桶中，这个过程也叫`rehash`。

如此的话，那么原来的`O(N)`就变成了`O(log(m/16,N))`，比如扩容成5倍那就是`O(log(5,N))`（以5为底，N的对数）。当这个底数较大的时候就会将N的对数压得非常低而和`O(1)`非常接近了，并且实际工程中基本是当成`O(1)`来用的。

你也许会说`rehash`很费时，会导致哈希表性能降低，这一点是可以侧面避免的。比如扩容时将倍数提高一些，那么`rehash`的次数就会很少，平衡到整个哈希表的使用来看，影响就甚微了。或者可以进行**离线扩容**，当需要扩容时，原哈希表还是供用户使用，在另外的内存中执行`rehash`，完成之后再将新表替换原表，这样的话对于用户来说，他是感觉不到`rehash`带来的麻烦的。

### 哈希表的JVM实现

在`Java`中，哈希表的实现是每个桶中放的是一棵**红黑树**而非链表，因为红黑树的查找效率很高，也是对哈希冲突带来的性能问题的一个优化。

## 布隆过滤器

不安全网页的黑名单包含100亿个黑名单网页，每个网页的URL最多占用64B。现在想要实现一种网页过滤系统，可以根据网页的URL判断该网页是否在黑名单上，请设计该系统。

要求如下：

1. 该系统允许有万分之一以下的判断失误率。
2. 使用的额外空间不要超过30GB。

如果将这100亿个URL通过数据库或哈希表保存起来，就可以对每条URL进行查询，但是每个URL有64B，数量是100亿个，所以至少需要640GB的空间，不满足要求2。

> 如果面试者遇到网页黑名单系统、垃圾邮件过滤系统，爬虫的网页判重系统等题目，又看到系统容忍一定程度的失误率，但是对空间要求比较严格，那么很可能是面试官希望面试者具备布隆过滤器的知识。一个布隆过滤器精确地代表一个集合，并可以精确判断一个元素是否在集合中。注意，只是精确代表和精确判断，到底有多精确呢？则完全在于你具体的设计，但想做到完全正确是不可能的。布隆过滤器的优势就在于使用很少的空间就可以将准确率做到很高的程度。该结构由`Burton Howard Bloom`于1970年提出。

那么什么是布隆过滤器呢？

假设有一个长度为`m`的bit类型的数组，即数组的每个位置只占一个bit，如果我们所知，每一个bit只有0和1两种状态，如图所示：

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/bloom.png) 

再假设一共有`k`个哈希函数，这些函数的输出域S都大于或等于m，并且这些哈希函数都足够优秀且彼此之间相互独立（将一个哈希函数的计算结果乘以6除以7得出的新哈希函数和原函数就是相互独立的）。那么对同一个输入对象（假设是一个字符串，记为URL），经过k个哈希函数算出来的结果也是独立的。可能相同，也可能不同，但彼此独立。对算出来的每一个结果都对m取余（%m），然后在bit array 上把相应位置设置为1（我们形象的称为涂黑）。如图所示

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/url_search.png) 

我们把bit类型的数组记为`bitMap`。至此，一个输入对象对`bitMap`的影响过程就结束了，也就是`bitMap`的一些位置会被涂黑。接下来按照该方法，处理所有的输入对象（黑名单中的100亿个URL）。每个对象都可能把`bitMap`中的一些白位置涂黑，也可能遇到已经涂黑的位置，遇到已经涂黑的位置让其继续为黑即可。处理完所有的输入对象后，可能`bitMap`中已经有相当多的位置被涂黑。至此，一个布隆过滤器生成完毕，这个布隆过滤器代表之前所有输入对象组成的集合。

那么在检查阶段时，如何检查一个对象是否是之前的某一个输入对象呢（判断一个URL是否是黑名单中的URL）？假设一个对象为a，想检查它是否是之前的输入对象，就把a通过k个哈希函数算出k个值，然后把k个值都取余（%m），就得到在[0,m-1]范围伤的k个值。接下来在`bitMap`上看这些位置是不是都为黑。如果有一个不为黑，说明a一定不再这个集合里。如果都为黑，说明a在这个集合里，但可能误判。

再解释具体一点，如果a的确是输入对象 ，那么在生成布隆过滤器时，`bitMap`中相应的k个位置一定已经涂黑了，所以在检查阶段，a一定不会被漏过，这个不会产生误判。会产生误判的是，a明明不是输入对象，但如果在生成布隆过滤器的阶段因为输入对象过多，而`bitMap`过小，则会导致`bitMap`绝大多数的位置都已经变黑。那么在检查a时，可能a对应的k个位置都是黑的，从而错误地认为a是输入对象（即是黑名单中的URL）。通俗地说，布隆过滤器的失误类型是“宁可错杀三千，绝不放过一个”。

布隆过滤器到底该怎么生成呢？只需记住下列三个公式即可：

- 对于输入的数据量n（这里是100亿）和失误率p（这里是万分之一），布隆过滤器的大小m：`m = - (n*lnp)/(ln2*ln2)`，计算结果向上取整（这道题m=19.19n，向上取整为20n，即需要2000亿个bit，也就是25GB）
- 需要的哈希函数的个数k：`k = ln2 * m/n = 0.7 * m/n`（这道题`k = 0.7 * 20n/n = 14`）
- 由于前两步都进行了向上取整，那么由前两步确定的布隆过滤器的真正失误率p：`p = (1 - e^(-nk/m))^k`

## 一致性哈希算法的基本原理

### 题目

工程师常使用服务器集群来设计和实现数据缓存，以下是常见的策略：

1. 无论是添加、查询还是珊瑚数据，都先将数据的id通过哈希函数换成一个哈希值，记为key
2. 如果目前机器有N台，则计算`key%N`的值，这个值就是该数据所属的机器编号，无论是添加、删除还是查询操作，都只在这台机器上进行。

请分析这种缓存策略可能带来的问题，并提出改进的方案。

### 解析

题目中描述的缓存从策略的潜在问题是，如果增加或删除机器时（N变化）代价会很高，所有的数据都不得不根据id重新计算一遍哈希值，并将哈希值对新的机器数进行取模啊哦做。然后进行大规模的数据迁移。

为了解决这些问题，下面介绍一下一致性哈希算法，这时一种很好的数据缓存设计方案。我们假设数据的id通过哈希函数转换成的哈希值范围是2^32，也就是0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形，那么一个数据id在计算出哈希值之后认为对应到环中的一个位置上，如图所示

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/consistent_hash.png) 

接下来想象有三台机器也处在这样一个环中，这三台机器在环中的位置根据机器id（主机名或者主机IP，是主机唯一的就行）设计算出的哈希值对2^32取模对应到环上。那么一条数据如何确定归属哪台机器呢？我们可以在该数据对应环上的位置顺时针寻找离该位置最近的机器，将数据归属于该机器上：

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/consistent_hash1.png) 

这样的话，如果删除`machine2`节点，则只需将`machine2`上的数据迁移到`machine3`上即可，而不必大动干戈迁移所有数据。当添加节点的时候，也只需将新增节点到逆时针方向新增节点前一个节点这之间的数据迁移给新增节点即可。

但这时还是存在如下两个问题：

- 机器较少时，通过机器id哈希将机器对应到环上之后，几个机器可能没有均分环

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/consistent_hash2.png) 

那么这样会导致负载不均。

+ 增加机器时，可能会打破现有的平衡：

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/consistent_hash3.png) 

为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一台机器通过不同的哈希函数计算出多个哈希值，对多个位置都放置一个服务节点，称为虚拟节点。具体做法：比如对于`machine1`的IP`192.168.25.132`（或机器名），计算出`192.168.25.132-1`、`192.168.25.132-2`、`192.168.25.132-3`、`192.168.25.132-4`的哈希值，然后对应到环上，其他的机器也是如此，这样的话节点数就变多了，根据哈希函数的性质，平衡性自然会变好：

![](https://raw.githubusercontent.com/Fi-Null/blog-pic/master/blog-pics/algorithms/consistent_hash5.png) 

此时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，比如上图的查找表。当某一条数据计算出归属于`m2-1`时再根据查找表的跳转，数据将最终归属于实际的m1节点。

> 基于一致性哈希的原理有很多种具体的实现，包括Chord算法、KAD算法等，有兴趣的话可以进一步学习。

## RandomPool

设计一种结构，在该结构中有如下三个功能：

- inserrt(key)：将某个key加入到该结构中，做到不重复加入。
- delete(key)：将原本在结构中的某个key移除。
- getRandom()：等概率随机返回结构中的任何一个key。

要求：insert、delete和getRandom方法的时间复杂度都是`O(1)`

> 思路：使用两个哈希表和一个变量`size`，一个表存放某`key`的标号，另一个表根据根据标号取某个`key`。`size`用来记录结构中的数据量。加入`key`时，将`size`作为该`key`的标号加入到两表中；删除`key`时，将标号最大的`key`替换它并将`size--`；随机取`key`时，将`size`范围内的随机数作为标号取`key`。

```java
import java.util.HashMap;

public class RandomPool {
    public int size;
    public HashMap<Object, Integer> keySignMap;
    public HashMap<Integer, Object> signKeyMap;

    public RandomPool() {
        this.size = 0;
        this.keySignMap = new HashMap<>();
        this.signKeyMap = new HashMap<>();
    }

    public void insert(Object key) {
        //不重复添加
        if (keySignMap.containsKey(key)) {
            return;
        }
        keySignMap.put(key, size);
        signKeyMap.put(size, key);
        size++;
    }

    public void delete(Object key) {
        if (keySignMap.containsKey(key)) {
            Object lastKey = signKeyMap.get(--size);
            int deleteSign = keySignMap.get(key);
            keySignMap.put(lastKey, deleteSign);
            signKeyMap.put(deleteSign, lastKey);
            keySignMap.remove(key);
            signKeyMap.remove(lastKey);
        }
    }

    public Object getRandom() {
        if (size > 0) {
            return signKeyMap.get((int) (Math.random() * size));
        }
        return null;
    }

}
```

# 小技巧

## 对数器

### 概述

有时我们对编写的算法进行测试时，会采用自己编造几个简单数据进行测试。然而别人测试时可能会将大数量级的数据输入进而测试算法的准确性和健壮性，如果这时出错，面对庞大的数据量我们将无从查起（是在操作哪一个数据时出了错，算法没有如期起作用）。当然我们不可能对这样一个大数据进行断点调试，去一步一步的分析错误点在哪。这时 **对数器** 就粉墨登场了，**对数器** 就是通过随机制造出几乎所有可能的简短样本作为算法的输入样本对算法进行测试，这样大量不同的样本从大概率上保证了算法的准确性，当有样本测试未通过时又能打印该简短样本对错误原因进行分析。

### 对数器的使用

1. 对于你想测试的算法
2. 实现功能与该算法相同但绝对正确、复杂度不好的算法
3. 准备大量随机的简短样本的
4. 实现比对的方法：对于每一个样本，比对该算法和第二步中算法的执行结果以判断该算法的正确性
5. 如果有一个样本比对出错则打印该样本
6. 当样本数量很多时比对测试依然正确，可以确定算法a已经正确

对数器使用案例——对自写的插入排序进行测试：

```java
void swap(int *a, int *b){
    int temp = *a;
    *a = *b;
    *b = temp;
}

//1.有一个自写的算法，但不知其健壮性（是否会有特殊情况使程序异常中断甚至崩溃）和正确性
void insertionSort(int arr[], int length){
    if(arr==NULL || length<=1){
        return;
    }
    for (int i = 1; i < length; ++i) {
        for (int j = i - 1; j >= 0 || arr[j] <= arr[j + 1]; j--) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
            }
        }
    }
}

//2、实现一个功能相同、绝对正确但复杂度不好的算法（这里摘取大家熟知的冒泡排序）
void bubbleSort(int arr[], int length) {
    for (int i = length-1; i > 0; i--) {
        for (int j = 0; j < i; ++j) {
            if (arr[j] > arr[j + 1]) {
                swap(&arr[j], &arr[j + 1]);
            }
        }
    }
}

//3、实现一个能够产生随机简短样本的方法
void generateSample(int arr[], int length){
    for (int i = 0; i < length; ++i) {
        arr[i] = rand() % 100-rand()%100;//控制元素在-100~100之间，考虑到零正负三种情况
    }
}

//4、实现一个比对测试算法和正确算法运算结果的方法
bool isEqual(int arr1[],int arr2[],int length) {
    if (arr1 != NULL && arr2 != NULL) {
        for (int i = 0; i < length; ++i) {
            if (arr1[i] != arr2[i]) {
                return false;
            }
        }
        return true;
    }
    return false;
}

void travels(int arr[], int length){
    for (int i = 0; i < length; ++i) {
        printf("%d ", arr[i]);
    }
    printf("\n");
}

void copy(int source[], int target[],int length){
    for (int i = 0; i < length; ++i) {
        target[i] = source[i];
    }
}

int main(){

    srand(time(NULL));
    int testTimes=10000;       
    //循环产生100000个样本进行测试
    for (int i = 0; i < testTimes; ++i) {
        int length = rand() % 10;   //控制每个样本的长度在10以内，便于出错时分析样本（因为简短）
        int arr[length];
        generateSample(arr, length);

      	//不要改变原始样本，在复制样本上改动
        int arr1[length], arr2[length];
        copy(arr, arr1, length);
        copy(arr, arr2, length);
        bubbleSort(arr1,length);
        insertionSort(arr2, length);

//        travels(arr, length);
//        travels(arr1, length);

      	//5、比对两个算法，只要有一个样本没通过就终止，并打印原始样本
        if (!isEqual(arr1, arr2, length)) {
            printf("test fail!the sample is: ");
            travels(arr, length);
            return 0;
        }
    }
   
  	//6、测试全部通过，该算法大概率上正确
    printf("nice!");
    return 0;
}
```

## 打印二叉树

有时我们不确定二叉树中是否有指针连空了或者连错了，这时需要将二叉树具有层次感地打印出来，下面就提供了这样一个工具。你可以将你的头逆时针旋转90度看打印结果。`v`表示该结点的头结点是左下方距离该结点最近的一个结点，`^`表示该结点的头结点是左上方距离该结点最近的一个结点。

```java
package top.zhenganwen.algorithmdemo.recursive;

public class PrintBinaryTree {

	public static class Node {
		public int value;
		public Node left;
		public Node right;

		public Node(int data) {
			this.value = data;
		}
	}

	public static void printTree(Node head) {
		System.out.println("Binary Tree:");
		printInOrder(head, 0, "H", 17);
		System.out.println();
	}

	public static void printInOrder(Node head, int height, String to, int len) {
		if (head == null) {
			return;
		}
		printInOrder(head.right, height + 1, "v", len);
		String val = to + head.value + to;
		int lenM = val.length();
		int lenL = (len - lenM) / 2;
		int lenR = len - lenM - lenL;
		val = getSpace(lenL) + val + getSpace(lenR);
		System.out.println(getSpace(height * len) + val);
		printInOrder(head.left, height + 1, "^", len);
	}

	public static String getSpace(int num) {
		String space = " ";
		StringBuffer buf = new StringBuffer("");
		for (int i = 0; i < num; i++) {
			buf.append(space);
		}
		return buf.toString();
	}

	public static void main(String[] args) {
		Node head = new Node(1);
		head.left = new Node(-222222222);
		head.right = new Node(3);
		head.left.left = new Node(Integer.MIN_VALUE);
		head.right.left = new Node(55555555);
		head.right.right = new Node(66);
		head.left.left.right = new Node(777);
		printTree(head);

		head = new Node(1);
		head.left = new Node(2);
		head.right = new Node(3);
		head.left.left = new Node(4);
		head.right.left = new Node(5);
		head.right.right = new Node(6);
		head.left.left.right = new Node(7);
		printTree(head);

		head = new Node(1);
		head.left = new Node(1);
		head.right = new Node(1);
		head.left.left = new Node(1);
		head.right.left = new Node(1);
		head.right.right = new Node(1);
		head.left.left.right = new Node(1);
		printTree(head);

	}
}
```
